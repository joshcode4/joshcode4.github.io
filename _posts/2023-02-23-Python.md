---
layout: post
title: Scraping book sale data using Python
categories: [p]
---

For this project, I used Python to scrape data from a website and load it into a csv. I was curious about the average review and price of these books, and I wanted this data all in one place. 

In order to execute this request, I created an empty .csv file to fill with this data, and then wrote the following code to scrape the webpages:

{% highlight c %}
import requests
from bs4 import BeautifulSoup as soup
import csv, time

url = "http://books.toscrape.com/"
file = open("books.csv","w")
headers = ["title","rating","price"]

writer = csv.DictWriter(file, fieldnames=headers)
writer.writeheader()
r = requests.get(url)
r

page = soup(r.text, 'html.parser')
boxes = page.find_all("article", {"class":"product_pod"})
len(boxes)
boxes[0]
boxes2 = page.find_all("p", {"class":"star-rating"})
boxes2[0]

import pandas as pd

def getContent(b): 
        price = b.find("p",{"class":"price_color"}).text.split("Â£")[1]
        rating = b.find("p",{"class":"star-rating"})["class"][1]
        title = b.find("h3").text
        writer.writerow({
            "title":title,
            "rating":rating,
            "price":price,
            })

def scrapePage(link):
        r = requests.get(link)
        page = soup(r.text,'html.parser')
        boxes = page.find_all("article",{"class":"product_pod"})
        for b in boxes:
            getContent(b)

page_numbers = list(range(1,51))

for p in page_numbers:
        front = "https://books.toscrape.com/catalogue/page-"
        page_url = front+str(p)+".html"
        time.sleep(1)
        scrapePage(page_url)
        time.sleep(1)
        print(f"scraping page {p}")

file.close()
}
{% endhighlight %}

When I concluded the operation, I had a csv file with 1000 books, organized into three columns by title, star rating out of 5, and price.
